{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbb41dff-2630-42a7-b459-ffadf1581003",
   "metadata": {},
   "source": [
    "# Search Algorithms and Complexity\n",
    "---\n",
    "\n",
    "## Notes:\n",
    "* Although I learned about data structures at university, it was a book called \"Grooking Algorithms\" that reinforced my basic knowledge in this area.\n",
    "* I strongly recommend reading the book [Entendendo Algoritmos (Grooking Algorithms in english)](https://a.co/d/hs3Qnev) written by [Aditya Y. Bhargava](https://www.adit.io/).\n",
    "* Dear reader, if you prefer a more visual way of learning Searching Algorithms, I highly recommend checking [VisuAlgo.net](https://visualgo.net/en/array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73293ccd-1bc8-41f5-9e82-700a79427382",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Sequential Search\n",
    "Sequential search, also known as linear search, is the simplest search algorithm for finding an element in a list. It works by checking each element of the list one by one until the target element is found or the end of the list is reached. Here are the main ideas behind sequential search and a Python implementation:\n",
    "\n",
    "### Main Ideas\n",
    "\n",
    "####  Unsorted List\n",
    "   * Sequential search works on both sorted and unsorted lists.\n",
    "\n",
    "#### Simple and Intuitive\n",
    "   - The algorithm is straightforward: start from the beginning of the list and check each element until the target is found or the list ends.\n",
    "\n",
    "#### Time Complexity\n",
    "   - The time complexity of sequential search is O(n), where (n) is the number of elements in the list. This means in the worst case, the algorithm has to check every element in the list.\n",
    "\n",
    "#### Comparison and Stopping Condition\n",
    "   - If the current element matches the target, the search is successful, and the index of the element is returned.\n",
    "   - If the end of the list is reached without finding the target, the search is unsuccessful, and typically -1 or another value indicating failure is returned.\n",
    "\n",
    "### Key Points\n",
    "\n",
    "- **Simplicity**: Sequential search is easy to understand and implement.\n",
    "- **Efficiency**: It is not the most efficient search algorithm, especially for large lists, since its time complexity is $O(n)$.\n",
    "- **Versatility**: It works on both sorted and unsorted lists, unlike binary search which requires the list to be sorted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "57d83928-3907-44bb-9d54-451f9c098f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple sequential search algorithm\n",
    "\n",
    "def sequentialSearch(res, data):\n",
    "    i = 0\n",
    "    while i < len(data):\n",
    "        if data[i] == res:\n",
    "            return i\n",
    "        else:\n",
    "            i += 1\n",
    "    else:\n",
    "        return -1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b558c6fe-aae7-4748-9340-b08fae2f5fcc",
   "metadata": {},
   "source": [
    "Running an example of the above function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cf0d27b-eab7-4973-b362-8f06bb121a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 9, 16, 2, 8, 13, 17, 12, 7, 0, 14, 10, 1, 15, 6, 19, 18, 3, 11]\n",
      "Selected value = 16\n",
      "Founded value at position 4\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "data = random.sample(range(20), 20)\n",
    "print(data)\n",
    "\n",
    "value = int(random.randint(0, 19))\n",
    "print(f\"Selected value = {value}\")\n",
    "\n",
    "searched = sequentialSearch(value, data)\n",
    "\n",
    "if searched == -1:\n",
    "    print(\"Value not found\")\n",
    "else:\n",
    "    print(f\"Founded value at position {searched}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7130b6-8d2b-4808-a688-4d9465c3fc32",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Binary Search\n",
    "Binary search is an efficient algorithm for finding an item from a sorted list of items. It works by repeatedly dividing the search interval in half\n",
    "\n",
    "### Main Ideas\n",
    "\n",
    "#### Sorted List Requirement\n",
    "* Binary search only works on sorted lists. The list must be ordered for the algorithm to be effective.\n",
    "   \n",
    "#### Divide and Conquer\n",
    "* The algorithm repeatedly divides the search range in half. If the list has (n) elements, the maximum number of steps needed to find the target is (log_2(n)).\n",
    "\n",
    "#### Comparison and Elimination\n",
    "   - Binary search starts by comparing the target value to the middle element of the list.\n",
    "   - If the middle element is equal to the target, the search is successful, and the index of the middle element is returned.\n",
    "   - If the target value is less than the middle element, the search continues on the left half of the list.\n",
    "   - If the target value is greater than the middle element, the search continues on the right half of the list.\n",
    "   - This process is repeated until the target value is found or the search interval is empty.\n",
    "\n",
    "### Key Points\n",
    "\n",
    "- **Efficiency**: Binary search has a time complexity of $O(\\log n)$, making it much faster than linear search for large lists.\n",
    "- **Applicability**: It is only applicable to sorted lists. If the list is not sorted, it must be sorted first, which has a time complexity of $O(n \\log n)$ using efficient sorting algorithms.\n",
    "- **Iterative vs Recursive**: Binary search can also be implemented recursively, which some may find more elegant but can lead to higher memory usage due to function call overhead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e5a53d6c-ccc5-4d04-a672-ac0e48a7258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple binary search algorithm\n",
    "\n",
    "def binarySearch(res, data):\n",
    "    data = sorted(data)\n",
    "    left = 0\n",
    "    right = len(data)\n",
    "    \n",
    "    # repeat until left == right or \"res\" is found\n",
    "    while left < right:\n",
    "        mid = int((left + right)/2)\n",
    "        \n",
    "        # If \"res\" is greater than the middle value, ignore the left half\n",
    "        if (res > data[mid]):\n",
    "            left = mid + 1\n",
    "        \n",
    "        # If \"res\" is smaller than the middle value, ignore the right half\n",
    "        elif (res < data[mid]):\n",
    "            right = mid - 1\n",
    "        \n",
    "        # if res == data[mid], then return \"mid\" (index)\n",
    "        else:\n",
    "            return mid\n",
    "\n",
    "    # If we reach here, the element was not present\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff07dede-c240-4b0f-bc39-9fb96f7c8ef6",
   "metadata": {},
   "source": [
    "Running an example of the above function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "49fb3106-4658-48d4-a9b7-25c0e608235d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29]\n",
      "Selected value = 6\n",
      "Founded value at position 6\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "data = random.sample(range(30), 25)\n",
    "print(sorted(data))\n",
    "\n",
    "value = int(random.randint(0, 20))\n",
    "print(f\"Selected value = {value}\")\n",
    "\n",
    "searched = binarySearch(value, data)\n",
    "\n",
    "if searched == -1:\n",
    "    print(\"Value not found\")\n",
    "else:\n",
    "    print(f\"Founded value at position {searched}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e13982-571d-46e7-bc6e-efa59a7e06f4",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Recursion\n",
    "---\n",
    "Recursion, is a powerful programming technique in which a function calls itself to solve a problem. This approach can simplify the code and solve problems that have a recursive nature, such as those that can be divided into similar sub-problems. Here are the main ideas behind recursion in Python:\n",
    "\n",
    "### Main Ideas\n",
    "\n",
    "#### Base Case\n",
    "   - Every recursive function must have a base case, which is a condition under which the function stops calling itself. Without a base case, the function would call itself indefinitely, leading to infinite recursion and a stack overflow error.\n",
    "\n",
    "#### Recursive Case\n",
    "   - Besides the base case, there is a recursive case, where the function calls itself with a modified argument, moving closer to the base case with each call.\n",
    "\n",
    "#### Stack Frame\n",
    "   - Each recursive call creates a new stack frame, which holds the function's parameters and local variables. When a base case is reached, the stack frames start to unwind, and the results are combined to give the final output.\n",
    "\n",
    "#### Divide and Conquer\n",
    "   - Many recursive algorithms follow the divide and conquer strategy, where the problem is divided into smaller sub-problems, solved individually, and then combined to form the final solution.\n",
    "\n",
    "### Key Points\n",
    "\n",
    "- **Simplicity**: Recursion can simplify the implementation of complex problems that have a recursive structure.\n",
    "\n",
    "- **Memory Usage**: Recursive functions can consume more memory than iterative ones because each function call adds a new frame to the call stack.\n",
    "\n",
    "- **Tail Recursion**: A special case of recursion where the recursive call is the last operation in the function. Some languages optimize tail-recursive functions to avoid stack overflow, but Python does not have this optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e5f81936-ef7f-46f9-aefd-0f89dd1cbd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "\n",
    "    # Base case: if n is 0, return 1\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    \n",
    "    # Recursive case: n! = n * (n-1)!\n",
    "    else:\n",
    "        return n * factorial(n - 1)\n",
    "\n",
    "def fibonacci(n):\n",
    "\n",
    "    # Base cases: F(0) = 0, F(1) = 1\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    \n",
    "    # Recursive case: F(n) = F(n-1) + F(n-2)\n",
    "    else:\n",
    "        return fibonacci(n - 1) + fibonacci(n - 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acf6731-7432-4a88-bc58-dd8ebc6bc5cd",
   "metadata": {},
   "source": [
    "Running an example with Factorial and Fibonacci:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "76caa988-b0f9-4884-9912-95be0d8708bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "number = 5\n",
    "\n",
    "print(factorial(5))  # Output: 5 * 4 * 3 * 2 * 1 = 120\n",
    "print(fibonacci(5))  # Output: 0 -> 1 -> 1 -> 2 -> 3 --> 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3319ab-7852-4a03-a660-02fa21ea6fe7",
   "metadata": {},
   "source": [
    "Time complexity is a measure used in computer science to describe the efficiency of an algorithm. It quantifies the amount of time an algorithm takes to run as a function of the size of its input. Here are the main ideas behind time complexity in programming:\n",
    "\n",
    "### Main Ideas\n",
    "\n",
    "#### Asymptotic Analysis\n",
    "   - Time complexity focuses on the behavior of an algorithm as the input size grows towards infinity. It provides a high-level understanding of the algorithm's efficiency without getting bogged down by machine-specific details or minor variations in performance.\n",
    "\n",
    "#### Big O Notation\n",
    "   - Big O notation is the most commonly used notation for expressing time complexity. It describes the upper bound of the algorithm's running time, providing a worst-case scenario. For example, $O(n)$, $O(log n)$, and $O(n^2)$ are different Big O notations representing different time complexities.\n",
    "\n",
    "#### Common Time Complexities\n",
    "   - $O(1)$ (Constant Time): The algorithm's running time is constant and does not change with the input size.\n",
    "   - $O(\\log n)$ (Logarithmic Time): The running time grows logarithmically with the input size. Examples include binary search.\n",
    "   - $O(n)$ (Linear Time): The running time grows linearly with the input size. Examples include linear search.\n",
    "   - $O(n \\log n)$ (Log-Linear Time): The running time grows faster than linear time but slower than quadratic time. Examples include efficient sorting algorithms like merge sort and quicksort.\n",
    "   - $O(n^2)$ (Quadratic Time): The running time grows quadratically with the input size. Examples include bubble sort and selection sort.\n",
    "   - Higher-order polynomials and exponential time complexities (e.g., $O(2^n)$) are less efficient and generally impractical for large inputs.\n",
    "\n",
    "#### Comparing Algorithms\n",
    "   - Time complexity allows us to compare the efficiency of different algorithms independently of hardware and implementation details. For example, an $O(n \\log n)$ sorting algorithm will generally outperform an $O(n^2)$ sorting algorithm for large inputs.\n",
    "\n",
    "#### Worst-Case, Best-Case, and Average-Case Analysis\n",
    "   - Worst-Case: The maximum time an algorithm takes to complete, regardless of the input.\n",
    "   - Best-Case: The minimum time an algorithm takes to complete.\n",
    "   - Average-Case: The expected time an algorithm takes to complete, averaged over all possible inputs.\n",
    "\n",
    "#### Space Complexity\n",
    "   - In addition to time complexity, space complexity measures the amount of memory an algorithm uses as a function of the input size. Both time and space complexity are important for evaluating the overall efficiency of an algorithm.\n",
    "\n",
    "### Practical Examples\n",
    "\n",
    "#### Example 1: Linear Search\n",
    "\n",
    "In a linear search, we check each element of the list one by one until we find the target element or reach the end of the list. The time complexity of linear search is $O(n)$, where $n$ is the number of elements in the list.\n",
    "\n",
    "```python\n",
    "def linear_search(arr, target):\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] == target:\n",
    "            return i\n",
    "    return -1\n",
    "```\n",
    "\n",
    "- **Best-Case**: $O(1)$ (Target is the first element)\n",
    "- **Worst-Case**: $O(n)$ (Target is the last element or not present)\n",
    "\n",
    "#### Example 2: Binary Search\n",
    "\n",
    "Binary search works on a sorted list by repeatedly dividing the search interval in half. The time complexity of binary search is $O(\\log n)$.\n",
    "\n",
    "```python\n",
    "def binary_search(arr, target):\n",
    "    left, right = 0, len(arr) - 1\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        elif arr[mid] < target:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "    return -1\n",
    "```\n",
    "\n",
    "- **Best-Case**: $O(1)$ (Target is the middle element)\n",
    "- **Worst-Case**: $O(\\log n)$ (Target is at one end or not present)\n",
    "\n",
    "### Visualization of Common Time Complexities\n",
    "\n",
    "Understanding the growth rates of different time complexities can be helpful. Here is a simple visualization:\n",
    "\n",
    "- **O(1)**: Constant Time  \n",
    "  |--------------------| (Stays the same regardless of input size)\n",
    "\n",
    "- **$O(\\log n)$**: Logarithmic Time  \n",
    "  |------|----|--|-| (Grows slowly as input size increases)\n",
    "\n",
    "- **O(n)**: Linear Time  \n",
    "  |-|--|----|------| (Grows directly with input size)\n",
    "\n",
    "- **$O(n log n)$**: Log-Linear Time  \n",
    "  |-|----|--------|----------------| (Grows faster than linear but not as fast as quadratic)\n",
    "\n",
    "- **$O(n^2)$**: Quadratic Time  \n",
    "  |-|-|----|--------|----------------|----------------------| (Grows much faster as input size increases)\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Time complexity is a crucial concept in evaluating the efficiency of algorithms. By using Big O notation, we can describe how an algorithm's running time grows with the input size, allowing us to compare and choose the most appropriate algorithm for a given problem. Understanding and analyzing time complexity helps in writing efficient and scalable code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
